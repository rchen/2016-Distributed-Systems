{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install jupyter\n",
    "\n",
    "```\n",
    "pip install jupyter\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter spark enviroment.\n",
    "```\n",
    "export PYSPARK_DRIVER_PYTHON=jupyter\n",
    "export PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\"\n",
    "pyspark --master local[2] --packages graphframes:graphframes:0.3.0-spark1.6-s_2.11 \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml.html as lh\n",
    "\n",
    "gdelt_base_url = 'http://data.gdeltproject.org/events/'\n",
    "\n",
    "page = requests.get(gdelt_base_url+'index.html')\n",
    "doc = lh.fromstring(page.content)\n",
    "link_list = doc.xpath(\"//*/ul/li/a/@href\")\n",
    "\n",
    "file_list = [x for x in link_list if str.isdigit(x[0:4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "today = datetime.today()\n",
    "tmpfiles = []\n",
    "while (1):\n",
    "    if len(tmpfiles) == 10:\n",
    "        break\n",
    "    date_string = today.strftime(\"%Y%m%d\") + \".export.CSV.zip\"\n",
    "    if date_string in file_list:\n",
    "        tmpfiles.append(date_string)\n",
    "    today -= timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import urllib\n",
    "import zipfile\n",
    "\n",
    "if not os.path.isdir('data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "rdd = None\n",
    "for download_file in tmpfiles:\n",
    "    zipfilename = './data/' + download_file\n",
    "    while not os.path.isfile(zipfilename):\n",
    "        urllib.urlretrieve(url=gdelt_base_url + download_file,\n",
    "                           filename=zipfilename)\n",
    "    zf = zipfile.ZipFile(file=zipfilename, mode='r')\n",
    "    for info in zf.infolist():\n",
    "        data = zf.read(info.filename)\n",
    "        tmprdd = sc.parallelize(data.split('\\n')).map(lambda line: line.split('\\t'))\n",
    "        if rdd:\n",
    "            rdd = sc.union([rdd, tmprdd])\n",
    "        else:\n",
    "            rdd = tmprdd\n",
    "    zf.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "Graphframes Documents: [http://graphframes.github.io/user-guide.html#pagerank](http://graphframes.github.io/user-guide.html#pagerank)\n",
    "\n",
    "Spark graphframes package: [https://spark-packages.org/package/graphframes/graphframes](https://spark-packages.org/package/graphframes/graphframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
